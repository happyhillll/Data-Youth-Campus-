{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"ÌÖçÏä§Ìä∏ ÏÉùÏÑ±Í∏∞: kogpt2_finetuning.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"2c0cf0d2d5994363bf6d1251b3ef7fa0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e9c91a7f6d0e48d088034d1740e1cdd1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_65449e15b6e748caa7af1c1b45ecefa0","IPY_MODEL_ea13875096604aa780a41eabb9e33407","IPY_MODEL_56521a8d135e40ce981d7f10552fb389"]}},"e9c91a7f6d0e48d088034d1740e1cdd1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"65449e15b6e748caa7af1c1b45ecefa0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ebbccef125a5466f980003b69d662a06","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"‚Äã","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_92febf788c7441eba1fc0341763ad92c"}},"ea13875096604aa780a41eabb9e33407":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_14041efacf0642ae9869264bd1599a7f","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":2825034,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2825034,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5ec3c61fd3484856942cd483b0f2f0ef"}},"56521a8d135e40ce981d7f10552fb389":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7d9956ef69a8455ba1b2f21c6d29a019","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"‚Äã","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2.83M/2.83M [00:00&lt;00:00, 3.61MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_df4353952d144a2da0911ba6febeb87e"}},"ebbccef125a5466f980003b69d662a06":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"92febf788c7441eba1fc0341763ad92c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"14041efacf0642ae9869264bd1599a7f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5ec3c61fd3484856942cd483b0f2f0ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7d9956ef69a8455ba1b2f21c6d29a019":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"df4353952d144a2da0911ba6febeb87e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4de30d4d7307408fa9479837fb48ce0a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_257d174973254a02bb2ee7b3d3398082","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e2eaa979ca6245198d48642a88edcbbc","IPY_MODEL_91d836c49586448c9734839b21b04645","IPY_MODEL_15d13e307ae14173bb8d862c9b09edeb"]}},"257d174973254a02bb2ee7b3d3398082":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e2eaa979ca6245198d48642a88edcbbc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_69fb1530eac844348ea5912df4c7775e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"‚Äã","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1a04cc7631a549f1acb085f948b0b15d"}},"91d836c49586448c9734839b21b04645":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ee1e190e984d4002b482462e69dd5927","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_07c2e3a13cea4fd0960cb9d432eb0faa"}},"15d13e307ae14173bb8d862c9b09edeb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_18fa2194002b4e40932fa66aa514fa7f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"‚Äã","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.00k/1.00k [00:00&lt;00:00, 18.1kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_06e3aa85fc6847e188d5ad63fdf4af86"}},"69fb1530eac844348ea5912df4c7775e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1a04cc7631a549f1acb085f948b0b15d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ee1e190e984d4002b482462e69dd5927":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"07c2e3a13cea4fd0960cb9d432eb0faa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"18fa2194002b4e40932fa66aa514fa7f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"06e3aa85fc6847e188d5ad63fdf4af86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ebf51224351242e9b5c8e0155c474172":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d2d273cc8f78487293a305e9551b5fce","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_bd17ed2f35d04f8ab04462653dedaf0b","IPY_MODEL_334bbe89fef045919ce341d5c05a27b5","IPY_MODEL_c1c470ced22947408703f2207df7164c"]}},"d2d273cc8f78487293a305e9551b5fce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bd17ed2f35d04f8ab04462653dedaf0b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b22e9a679f504e4ca982c908d45ab09e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"‚Äã","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_830a8c1d8d43461f89ba4a543f684e33"}},"334bbe89fef045919ce341d5c05a27b5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_29a077119fcd410cbf18c2fc7800c443","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":513302779,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":513302779,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_da37f631b0034253b430a4ed0b927c00"}},"c1c470ced22947408703f2207df7164c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4ed279ebcbc549199bbede633f8b2b29","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"‚Äã","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 513M/513M [00:16&lt;00:00, 34.8MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_949047ef16ec4512b383cf900ac5bed0"}},"b22e9a679f504e4ca982c908d45ab09e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"830a8c1d8d43461f89ba4a543f684e33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"29a077119fcd410cbf18c2fc7800c443":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"da37f631b0034253b430a4ed0b927c00":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4ed279ebcbc549199bbede633f8b2b29":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"949047ef16ec4512b383cf900ac5bed0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"GcDSObPuqPr7"},"source":["#ÌïÑÏöîÌïú ÌååÏùº Îã§Ïö¥Î°úÎìú"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1ciDG7f5qV_E","executionInfo":{"status":"ok","timestamp":1629866884321,"user_tz":-540,"elapsed":9266,"user":{"displayName":"‚ÄçÍπÄÎØºÏßÄ[Ïû¨Ìïô / ÎèôÏïÑÌîÑÎ¶¨Ïπ¥Ïñ¥Ï†ÑÍ≥µ]","photoUrl":"","userId":"06217683100035561585"}},"outputId":"9777b9be-8206-4970-aceb-4bcef9cb5f7c"},"source":["!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","  Downloading transformers-4.9.2-py3-none-any.whl (2.6 MB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.6 MB 13.8 MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.3 MB 29.8 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n","Collecting huggingface-hub==0.0.12\n","  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 895 kB 38.8 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 636 kB 34.1 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.0.12 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fD9BGjOKFuX1","colab":{"base_uri":"https://localhost:8080/","height":228},"executionInfo":{"status":"error","timestamp":1629868452926,"user_tz":-540,"elapsed":401,"user":{"displayName":"‚ÄçÍπÄÎØºÏßÄ[Ïû¨Ìïô / ÎèôÏïÑÌîÑÎ¶¨Ïπ¥Ïñ¥Ï†ÑÍ≥µ]","photoUrl":"","userId":"06217683100035561585"}},"outputId":"06f0b86a-b1b2-4d60-82f8-8751f9924df6"},"source":["import pandas as pd\n","\n","#df = pd.read_csv(\"/content/prep_text.txt\", encoding=\"utf-8\")\n","df=open('/content/prep_text.txt',encoding=\"utf-8\")\n","\n","#text_data = open('/content/brunch.txt', 'w', encoding=\"utf-8\")\n","text_data = open('/content/essay.txt','w',encoding = 'utf-8')\n","\n","\n","texts = df['0']\n","for t in texts:\n","    \n","    if '*' in t:\n","        continue\n","    if '#' in t:\n","        continue\n","    if 'http' in t :\n","        continue\n","    if '@' in t:\n","        continue\n","    if ':' in t:\n","        continue\n","    text_data.write(t + '\\n')\n","text_data.close()"],"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-61c420c2fc9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: '_io.TextIOWrapper' object is not subscriptable"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":604,"referenced_widgets":["2c0cf0d2d5994363bf6d1251b3ef7fa0","e9c91a7f6d0e48d088034d1740e1cdd1","65449e15b6e748caa7af1c1b45ecefa0","ea13875096604aa780a41eabb9e33407","56521a8d135e40ce981d7f10552fb389","ebbccef125a5466f980003b69d662a06","92febf788c7441eba1fc0341763ad92c","14041efacf0642ae9869264bd1599a7f","5ec3c61fd3484856942cd483b0f2f0ef","7d9956ef69a8455ba1b2f21c6d29a019","df4353952d144a2da0911ba6febeb87e","4de30d4d7307408fa9479837fb48ce0a","257d174973254a02bb2ee7b3d3398082","e2eaa979ca6245198d48642a88edcbbc","91d836c49586448c9734839b21b04645","15d13e307ae14173bb8d862c9b09edeb","69fb1530eac844348ea5912df4c7775e","1a04cc7631a549f1acb085f948b0b15d","ee1e190e984d4002b482462e69dd5927","07c2e3a13cea4fd0960cb9d432eb0faa","18fa2194002b4e40932fa66aa514fa7f","06e3aa85fc6847e188d5ad63fdf4af86","ebf51224351242e9b5c8e0155c474172","d2d273cc8f78487293a305e9551b5fce","bd17ed2f35d04f8ab04462653dedaf0b","334bbe89fef045919ce341d5c05a27b5","c1c470ced22947408703f2207df7164c","b22e9a679f504e4ca982c908d45ab09e","830a8c1d8d43461f89ba4a543f684e33","29a077119fcd410cbf18c2fc7800c443","da37f631b0034253b430a4ed0b927c00","4ed279ebcbc549199bbede633f8b2b29","949047ef16ec4512b383cf900ac5bed0"]},"id":"_CY1a8xDAXr9","executionInfo":{"status":"ok","timestamp":1629868100998,"user_tz":-540,"elapsed":1178616,"user":{"displayName":"‚ÄçÍπÄÎØºÏßÄ[Ïû¨Ìïô / ÎèôÏïÑÌîÑÎ¶¨Ïπ¥Ïñ¥Ï†ÑÍ≥µ]","photoUrl":"","userId":"06217683100035561585"}},"outputId":"133e9536-4dce-4f15-ace3-a34b722cced8"},"source":["from transformers import TextDataset, DataCollatorForLanguageModeling\n","from transformers import GPT2LMHeadModel\n","from transformers import Trainer, TrainingArguments\n","from transformers import PreTrainedTokenizerFast\n","\n","def load_dataset(file_path, tokenizer, block_size = 128):\n","    dataset = TextDataset(\n","        tokenizer = tokenizer,\n","        file_path = file_path,\n","        block_size = block_size,\n","    )\n","    return dataset\n","\n","def load_data_collator(tokenizer, mlm = False):\n","    data_collator = DataCollatorForLanguageModeling(\n","        tokenizer=tokenizer, \n","        mlm=mlm,\n","    )\n","    return data_collator\n","\n","\n","def train(train_file_path,model_name,\n","          output_dir,\n","          overwrite_output_dir,\n","          per_device_train_batch_size,\n","          num_train_epochs,\n","          save_steps):\n","  tokenizer = PreTrainedTokenizerFast.from_pretrained(model_name)\n","  train_dataset = load_dataset(train_file_path, tokenizer)\n","  data_collator = load_data_collator(tokenizer)\n","\n","  tokenizer.save_pretrained(output_dir, legacy_format=False)\n","   \n","  model = GPT2LMHeadModel.from_pretrained(model_name)\n","\n","  model.save_pretrained(output_dir)\n","\n","  training_args = TrainingArguments(\n","          output_dir=output_dir,\n","          overwrite_output_dir=overwrite_output_dir,\n","          per_device_train_batch_size=per_device_train_batch_size,\n","          num_train_epochs=num_train_epochs,\n","      )\n","\n","  trainer = Trainer(\n","          model=model,\n","          args=training_args,\n","          data_collator=data_collator,\n","          train_dataset=train_dataset,\n","  )\n","      \n","  trainer.train()\n","  trainer.save_model()\n","\n","\n","train_file_path = '/content/prep_text.txt'\n","model_name = 'skt/kogpt2-base-v2'\n","output_dir = './modelv5'\n","overwrite_output_dir = False\n","per_device_train_batch_size =16\n","num_train_epochs = 3\n","save_steps = 500\n","\n","train(\n","    train_file_path=train_file_path,\n","    model_name=model_name,\n","    output_dir=output_dir,\n","    overwrite_output_dir=overwrite_output_dir,\n","    per_device_train_batch_size=per_device_train_batch_size,\n","    num_train_epochs=num_train_epochs,\n","    save_steps=save_steps\n",")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2c0cf0d2d5994363bf6d1251b3ef7fa0","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/2.83M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4de30d4d7307408fa9479837fb48ce0a","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n","The class this function is called from is 'PreTrainedTokenizerFast'.\n","/usr/local/lib/python3.7/dist-packages/transformers/data/datasets/language_modeling.py:58: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ü§ó Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_mlm.py\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ebf51224351242e9b5c8e0155c474172","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/513M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","text":["***** Running training *****\n","  Num examples = 4399\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 825\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='825' max='825' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [825/825 14:29, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>4.276000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","text":["Saving model checkpoint to ./modelv5/checkpoint-500\n","Configuration saved in ./modelv5/checkpoint-500/config.json\n","Model weights saved in ./modelv5/checkpoint-500/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Saving model checkpoint to ./modelv5\n","Configuration saved in ./modelv5/config.json\n","Model weights saved in ./modelv5/pytorch_model.bin\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"em51VgI2AiBK"},"source":["from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\n","\n","def load_model(model_path):\n","    model = GPT2LMHeadModel.from_pretrained(model_path)\n","    return model\n","\n","\n","def load_tokenizer(tokenizer_path):\n","    tokenizer = PreTrainedTokenizerFast.from_pretrained(tokenizer_path)\n","    return tokenizer\n","\n","\n","def generate_text(sequence, max_length):\n","    model_path = \"./modelv5\"\n","    model = load_model(model_path)\n","    tokenizer = load_tokenizer(model_path)\n","    ids = tokenizer.encode(f'{sequence},', return_tensors='pt')\n","    final_outputs = model.generate(\n","        ids,\n","        do_sample=True,\n","        max_length=max_length,\n","        pad_token_id=model.config.pad_token_id,\n","        top_k=50,\n","        top_p=0.95,\n","    )\n","    return(tokenizer.decode(final_outputs[0], skip_special_tokens=True))\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G8wbWza0MaiH","executionInfo":{"status":"ok","timestamp":1629868794947,"user_tz":-540,"elapsed":292759,"user":{"displayName":"‚ÄçÍπÄÎØºÏßÄ[Ïû¨Ìïô / ÎèôÏïÑÌîÑÎ¶¨Ïπ¥Ïñ¥Ï†ÑÍ≥µ]","photoUrl":"","userId":"06217683100035561585"}},"outputId":"46722542-c7e5-43c9-ef7b-60ca16d1431d"},"source":["#Ï†úÏùº Í∏∞Î≥∏ ÏΩîÎìú\n","input = 'ÏóêÌé†ÌÉë'\n","\n","sequence = input\n","max_len = 300\n","\n","\n","\n","for i in range(3):\n","   \n","\n","    sequence = input\n","    max_len = 1000\n","\n","    print('input :' + sequence)\n","    print('=' * 50)\n","\n","    g = generate_text(sequence, max_len)\n","    g = g.split('<eos>')[0]\n","    g = g.split(',')[2:]\n","    g = ', '.join(g)\n","    input = g.split('\\n')\n","    input = input[-1]\n","    print(g)\n","    \n","\n","    \n","print('=' * 50)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["loading configuration file ./modelv5/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n","  \"_num_labels\": 1,\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n","  \"bos_token_id\": 0,\n","  \"created_date\": \"2021-04-28\",\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"license\": \"CC-BY-NC-SA 4.0\",\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 3,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","loading weights file ./modelv5/pytorch_model.bin\n"],"name":"stderr"},{"output_type":"stream","text":["input :ÏóêÌé†ÌÉë\n","==================================================\n"],"name":"stdout"},{"output_type":"stream","text":["All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./modelv5.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","Didn't find file ./modelv5/added_tokens.json. We won't load it.\n","loading file None\n","loading file ./modelv5/special_tokens_map.json\n","loading file ./modelv5/tokenizer_config.json\n","loading file ./modelv5/tokenizer.json\n","loading configuration file ./modelv5/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n","  \"_num_labels\": 1,\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n","  \"bos_token_id\": 0,\n","  \"created_date\": \"2021-04-28\",\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"license\": \"CC-BY-NC-SA 4.0\",\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 3,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","loading weights file ./modelv5/pytorch_model.bin\n"],"name":"stderr"},{"output_type":"stream","text":["\n","input :\n","==================================================\n"],"name":"stdout"},{"output_type":"stream","text":["All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./modelv5.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","Didn't find file ./modelv5/added_tokens.json. We won't load it.\n","loading file None\n","loading file ./modelv5/special_tokens_map.json\n","loading file ./modelv5/tokenizer_config.json\n","loading file ./modelv5/tokenizer.json\n","loading configuration file ./modelv5/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n","  \"_num_labels\": 1,\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n","  \"bos_token_id\": 0,\n","  \"created_date\": \"2021-04-28\",\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"license\": \"CC-BY-NC-SA 4.0\",\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 3,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","loading weights file ./modelv5/pytorch_model.bin\n"],"name":"stderr"},{"output_type":"stream","text":["\n","input :\n","==================================================\n"],"name":"stdout"},{"output_type":"stream","text":["All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./modelv5.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","Didn't find file ./modelv5/added_tokens.json. We won't load it.\n","loading file None\n","loading file ./modelv5/special_tokens_map.json\n","loading file ./modelv5/tokenizer_config.json\n","loading file ./modelv5/tokenizer.json\n"],"name":"stderr"},{"output_type":"stream","text":["\n","==================================================\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HfvwH_z6NlKP","executionInfo":{"status":"ok","timestamp":1629869842666,"user_tz":-540,"elapsed":59271,"user":{"displayName":"‚ÄçÍπÄÎØºÏßÄ[Ïû¨Ìïô / ÎèôÏïÑÌîÑÎ¶¨Ïπ¥Ïñ¥Ï†ÑÍ≥µ]","photoUrl":"","userId":"06217683100035561585"}},"outputId":"6481148c-19fe-41c0-b057-085a495a0fea"},"source":["#keywordÏóê Îî∞Î•∏ Ï∂úÎ†•\n","generated_texts = []\n","keywords = ['ÌååÎ¶¨','Î£®Î∏åÎ•¥','ÏóêÌé†ÌÉë']\n","\n","for key in keywords:\n","    #input_data = input('ÌÇ§ÏõåÎìú ÏûÖÎ†• :')\n","    #keywords.append(input_data)\n","    input_data = key.split(' ')\n","    #keywords.append(input)\n","\n","    #max_len = 300\n","    total = ''\n","\n","    for i in input_data:\n","        max_len = 200\n","\n","        #print('input :' + i)\n","        #print('=' * 50)\n","\n","        g = generate_text(','+i, max_len)\n","        g = g.split('<eos>')[0]\n","        g = g.split(',')[2:]\n","        g = ', '.join(g)\n","\n","        t =''\n","        data = g.split('\\n')\n","        data = data[:-1]\n","        for d in data: \n","            t += d + '\\n'\n","\n","        total += '\\n\\t(' + i +')'  + t\n","        \n","    print('=' * 50)\n","    print(\"<generated_text>\")\n","    print(total)\n","    print('=' * 50)\n","    generated_texts.append(total)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["loading configuration file ./modelv5/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n","  \"_num_labels\": 1,\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n","  \"bos_token_id\": 0,\n","  \"created_date\": \"2021-04-28\",\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"license\": \"CC-BY-NC-SA 4.0\",\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 3,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","loading weights file ./modelv5/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./modelv5.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","Didn't find file ./modelv5/added_tokens.json. We won't load it.\n","loading file None\n","loading file ./modelv5/special_tokens_map.json\n","loading file ./modelv5/tokenizer_config.json\n","loading file ./modelv5/tokenizer.json\n","loading configuration file ./modelv5/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n","  \"_num_labels\": 1,\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n","  \"bos_token_id\": 0,\n","  \"created_date\": \"2021-04-28\",\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"license\": \"CC-BY-NC-SA 4.0\",\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 3,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","loading weights file ./modelv5/pytorch_model.bin\n"],"name":"stderr"},{"output_type":"stream","text":["==================================================\n","<generated_text>\n","\n","\t(ÌååÎ¶¨) ÌååÎ¶¨Í∞Ä ÏïÑÎãå ÌîÑÎûëÏä§ÎùºÎäî ÎÇòÎùºÏùò ÏàòÎèÑÎäî ÌîÑÎûëÏä§ ÌååÎ¶¨Í∞Ä ÏïÑÎãàÎã§\n","ÌååÎ¶¨ ÏßÄÌïòÏ≤† ÎÖ∏ÏÑ†Ïùò Ï¢ÖÏ†ê ÌååÎ¶¨Ïó≠ Î™ΩÎßàÎ•¥Ìä∏Î•¥ Ïñ∏Îçï ÏúÑ ÌååÎ¶¨Ïó≠Ïùò Î™ΩÎßàÎ•¥Ìä∏Î•¥ Ïñ∏ÎçïÏóê Ïò§Î•¥Îäî ÏùºÏùÄ Ïù¥ Îëê ÎèÑÏãúÍ∞Ä ÎÇ¥Í≤å Îòê Îã§Î•∏ Î¨òÎØ∏Î•º ÏÑ†ÏÇ¨Ìï¥Ï§Ñ Í≤ÉÏù¥ÎùºÍ≥† ÎØøÏóàÎã§\n","Í∑∏Í≥≥ÏóêÏÑú ÌååÎ¶¨ÏßÄÏïµÎì§ÏùÄ Îß§ÏùºÍ∞ôÏù¥ ÌïúÏãùÎãπÏóêÏÑú Ïª§ÌîºÎ•º ÎßàÏãúÎäîÎã§\n","Ïπ¥Ìéò Î†àÏä§ÌÜ†ÎûëÏóêÏÑú ÌïúÏãùÏùÑ Î®πÎã§Îãà ÌååÎ¶¨ Ïó¨Ìñâ Ï§ë Ïª§Ìîº Ìïú ÏûîÎèÑ Î™ª ÎßàÏãúÍ≥† Î∞îÎ°ú ÏòÜÏóê Ïπ¥ÌéòÏóê ÏïâÏïÑ Ïª§ÌîºÎ•º ÎßàÏãúÎã§ Î≥¥Î©¥ Îëê ÎèÑÏãú Î™®Îëê ÏÉâÎã§Î•∏ ÎäêÎÇåÏùò ÌååÎ¶¨ Ïó¨ÌñâÏùÑ Ìï† Ïàò ÏûàÏóàÎã§\n","ÌååÎ¶¨ Ïπ¥ÌéòÎ•º Í±∞ÎãêÎã§ Î≥¥Î©¥ Ïπ¥ÌéòÏóê ÏïâÏïÑÏûàÎã§Í∞ÄÎèÑ ÌååÎ¶¨ÏßÄÏïµÏù¥ ÎßåÎì† ÎèÑÏãúÎùΩÏóê ÎùºÎñºÎ•º ÎßàÏã†Îã§\n","ÌååÎ¶¨ÏßÄÏïµÍ≥º Ïó¨ÌñâÌïòÎäî ÌååÎ¶¨ÏßÄÏïµÏóêÍ≤å ÌååÎ¶¨Ïùò ÎèÑÏãúÎäî Îòê Îã§Î•∏ Î¨òÎØ∏Î•º ÏÑ†ÏÇ¨Ìï† Í≤ÉÏù¥Îã§\n","ÌååÎ¶¨Îäî Ïó¨Ï†ÑÌûà Ïó¨ÌñâÏùò Ïû¨ÎØ∏Ïóê Í¥ÄÏã¨Ïù¥ ÎßéÏùÄ ÎèÑÏãúÏù¥Îã§\n","Ïù¥ ÎèÑÏãúÎäî ÌååÎ¶¨ÏßÄÏïµÏù¥ Î®πÍ≥† ÏûêÎäî Í≥≥Ïù¥Îã§\n","ÌååÎ¶¨Îäî ÌïòÎ£® ÎèôÏïà Îß§Ïùº ÏïÑÏπ® 9Ïãú 30Î∂ÑÍ≤Ω Î¨∏ÏùÑ Ïó¥Í≥† ÌååÎ¶¨ÏßÄÏïµÏùÄ 9ÏãúÍπåÏßÄ Ïª§ÌîºÎ•º ÎßàÏã§ Ïàò ÏûàÎã§\n","\n","==================================================\n"],"name":"stdout"},{"output_type":"stream","text":["All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./modelv5.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","Didn't find file ./modelv5/added_tokens.json. We won't load it.\n","loading file None\n","loading file ./modelv5/special_tokens_map.json\n","loading file ./modelv5/tokenizer_config.json\n","loading file ./modelv5/tokenizer.json\n","loading configuration file ./modelv5/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n","  \"_num_labels\": 1,\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n","  \"bos_token_id\": 0,\n","  \"created_date\": \"2021-04-28\",\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"license\": \"CC-BY-NC-SA 4.0\",\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 3,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","loading weights file ./modelv5/pytorch_model.bin\n"],"name":"stderr"},{"output_type":"stream","text":["==================================================\n","<generated_text>\n","\n","\t(Î£®Î∏åÎ•¥)ÎèÑÎπå Îì±Ïùò ÎèÑÏãú Ï§ëÏã¨ÏßÄÏôÄ Î©ÄÏßÄ ÏïäÏùÄ Í≥≥Ïóê ÏúÑÏπòÌï¥ ÏûàÎäîÎç∞ Í∑∏Ï§ë Í∞ÄÏû• Ïú†Î™ÖÌïú ÏßÄÏó≠ÏùÄ ÌååÎ¶¨Ïùò ÎÖ∏Ìä∏Î•¥Îã¥ ÎåÄÏÑ±ÎãπÏù¥Îùº Î∂àÎ¶¨Îäî Î£®Î∏åÎ•¥Î°ú Í∑∏ Ïó≠ÏÇ¨Í∞Ä ÍΩ§ Ïò§ÎûòÎêú Í≥≥Ïù¥Îã§\n","Î£®Î∏åÎ•¥ Î∞ïÎ¨ºÍ¥ÄÏóêÎäî ÎßéÏùÄ Í≥†ÎåÄ Ïú†Î¨ºÎì§Ïù¥ Ï†ÑÏãúÎêòÏñ¥ ÏûàÎäîÎç∞ Î£®Î∏åÎ•¥Îäî Í≥†ÎåÄ Í∑∏Î¶¨Ïä§ Ïã†ÌôîÏóê ÎÇòÏò§Îäî Ïò§ÎîîÏÑ∏Ïö∞Ïä§ÎùºÎäî Ïù∏Î¨º ÏÉÅÎåÄÏùò Ïù¥Î¶ÑÏù¥ Îì§Ïñ¥ÏûàÍ±∞ÎÇò Ïã†Ìôî ÏÜçÏùò Ïò§ÎîîÏÑ∏Ïö∞Ïä§ÏôÄ Í∞ôÏùÄ Ïù∏Î¨ºÏù¥ Ï°∞Í∞ÅÎêòÏñ¥ ÏûàÍ≥† Í∑∏ ÏòÜÏóê Ïò§ÎîîÏÑ∏Ïö∞Ïä§Í∞Ä ÏïâÏïÑÏûàÎäî Í≥≥Ïù¥ Î∞îÎ°ú ÎÖ∏Ìä∏Î•¥Îã¥ ÎåÄÏÑ±Îãπ\n","Í∑∏ ÏòõÎÇ† Í∑∏Î¶¨Ïä§Ïùò Ìó§ÎùºÌÅ¥Î†àÏä§Í∞Ä Ïù¥ Í≥≥ÏóêÏÑú ÏÇ¥ÏïòÎã§Í≥† ÌïúÎã§\n","Í∑∏Î¶¨Í≥† Ïù¥ Í≥≥ÏóêÏÑú Î£®Î∏åÎ•¥Îäî ÏÑ±Î™® ÎßàÎ¶¨ÏïÑÍ∞Ä ÌÉÑÏÉùÌï† ÎãπÏãú ÏÇ¨ÎûåÎì§Ïù¥ ÎßéÏù¥ ÏÇ¥ÏïòÎçò Í≥≥ÏúºÎ°ú ÏßÄÍ∏àÎèÑ ÎßéÏùÄ ÏÇ¨ÎûåÎì§Ïù¥ Ï∞æÏúºÎ©¥ÏÑú Ïú†Î™ÖÌïòÍ≥† ÏûàÎã§\n","Î£®Î∏åÎ•¥ Î∞ïÎ¨ºÍ¥ÄÏúºÎ°ú ÏûÖÏû•ÌïòÎ©¥ ÏÑ±Îãπ ÎÇ¥Î∂ÄÏóê ÏûàÎäî ÏóêÏÑú ÏÑ±Îãπ ÎÇ¥Î∂ÄÎ•º Í∞êÏÉÅÌïòÍ≥† ÏßÄÌïòÏ≤†Ïóê ÎÇ¥Î†§ Í≥µÏõê ÏÇ∞Ï±ÖÎ°úÎ°ú ÎÇòÍ∞ÄÎ©¥ ÎêúÎã§\n","Ïó≠Ïãú ÌååÎ¶¨Ïùò ÎûúÎìúÎßàÌÅ¨Î°ú Î∂àÎ¶¨Îäî Ïù¥ ÏÑ±ÎãπÏùÄ Ïö∞Î¶¨ÎÇòÎùºÏóêÎèÑ Ïûò ÏïåÎ†§ÏßÑ Í≥≥Ïù¥Îã§\n","Î£®Î∏åÎ•¥ Î∞ïÎ¨ºÍ¥ÄÍ≥º ÎßàÏ∞¨Í∞ÄÏßÄÎ°ú 19ÏÑ∏Í∏∞ ÎßêÍ≥º 20ÏÑ∏Í∏∞ Ï¥à ÏÇ¨Ïù¥Ïóê ÏßÄÏñ¥ÏßÑ Í±¥Î¨ºÎ°ú ÏõêÎûòÎäî ÏõêÎûò Ïù¥ ÏÑ±ÎãπÏúºÎ°ú ÏÇ¨Ïö©ÌïòÎã§Í∞Ä 1917ÎÖÑ Ïû¨Í±¥ÎêòÏñ¥ ÌòÑÏû¨Ïóê Ïù¥Î•∏Îã§\n","\n","==================================================\n"],"name":"stdout"},{"output_type":"stream","text":["All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./modelv5.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","Didn't find file ./modelv5/added_tokens.json. We won't load it.\n","loading file None\n","loading file ./modelv5/special_tokens_map.json\n","loading file ./modelv5/tokenizer_config.json\n","loading file ./modelv5/tokenizer.json\n"],"name":"stderr"},{"output_type":"stream","text":["==================================================\n","<generated_text>\n","\n","\t(ÏóêÌé†ÌÉë)Í∑∏Î¶¨Í≥† ÏóêÌé†ÌÉëÏù¥ ÏûàÎäî Í≥≥Ïóê ÎåÄÌïú ÏÜåÍ∞úÎäî ÏïÑÏßÅ ÏóÜÏßÄÎßå ÏóêÌé†ÌÉëÏù¥ ÏûàÎäî Í≥≥Ïóê ÎåÄÌïú ÏÜåÍ∞úÎäî ÏïÑÏßÅ ÏãúÏûëÎêòÏßÄ ÏïäÏïòÎã§\n","Ïò§Ìîà Ï†ÑÎ∂ÄÌÑ∞ ÎßéÏùÄ Ïù∏ÌååÍ∞Ä Î™®ÏòÄÎäîÎç∞ Í∑∏ÎïåÎ∂ÄÌÑ∞ ÎßéÏùÄ ÏÇ¨ÎûåÎì§ÏóêÍ≤å Ïù∏Í∏∞Î•º ÏñªÍ≥† ÏûàÍ≥† ÏïÑÏßÅ ÎßâÎ∞îÏßÄÏù∏Îç∞ÎèÑ ÎßéÏùÄ ÏÇ¨ÎûåÎì§Ïù¥ ÏóêÌé†ÌÉëÏóê ÏûàÎäî ÏÇ¨ÏßÑÎì§ÏùÑ Ïò¨Î†§ÎÜìÏïòÏúºÎ©¥ Ï¢ãÍ≤†Îã§Í≥†\n","Ï¢ãÏïÑÌïúÎã§\n","Í∑∏Îû¨ÎçîÎãà ÎÇ¥Í∞Ä ÏÇ¨ÏßÑÏùÑ Ï∞çÏóàÎçîÎãà Í¥úÏ∞ÆÏïÑ ÎùºÎäî ÎßêÏù¥ ÎêòÏóàÎã§\n","Ïñ¥Ï®åÍ±∞ÎÇò ÏÇ¨ÏßÑÎì§ÏùÑ Î≥¥Îãà Ïô†ÏßÄ Î≠îÏßÄ Î™®Î•¥Í≤å ÏóêÌé†ÌÉëÏóê ÎåÄÌïú Ï†ïÎ≥¥Í∞Ä Î®∏Î¶øÏÜçÏóê Îß¥ÎèåÏïòÎã§\n","ÏïÑÎ¨¥ÎûòÎèÑ Ïûò Î™®Î•¥Í≤†Ïñ¥ÏÑú Í∑∏Ï†Ä Î©çÌïòÎãà Î∞îÎùºÎ≥¥Îã§Í∞Ä ÏóêÌé†ÌÉëÏóê ÎåÄÌï¥ÏÑú Îã§Ïãú ÌïúÎ≤à ÏÉùÍ∞ÅÌï¥Î≥¥Í≤å ÎêòÏóàÎã§\n","Ïñ¥Ï®åÎì† Ïù¥Î†áÍ≤å ÏÉùÍ∞ÅÌïòÎ©∞ ÏóêÌé†ÌÉëÏùÑ Îã§Ïãú Î≥¥ÏïòÎã§\n","ÎÇòÎäî Í∑∏ Ïû•ÏÜåÏóê ÎåÄÌï¥ÏÑú Îã§Ïãú ÎèåÏïÑÎã§ÎÖÄÏÑú Îã§Ïãú Î≥¥Í≤å ÎêòÏóàÎã§\n","Ïù¥Ï†úÎäî Ï∂îÏñµÏù¥ ÎêúÎã§\n","ÌååÎûÄ ÌïòÎäòÏóê Îñ†ÏûàÎäî ÏóêÌé†ÌÉë\n","Ïù¥Î†áÍ≤å Î≥¥Î©¥ ÎßàÏπò ÌååÎ¶¨Ïùò Í≤®Ïö∏Ï≤òÎüº Í≤®Ïö∏ Í∞ôÏïòÎã§\n","Í∑∏Î¶¨Í≥† ÏïÑÏßÅÎèÑ Í∑∏ Ïû•ÏÜåÏóê ÎåÄÌïú Í∏∞ÏñµÏù¥ Ïó¨Ï†ÑÌûà Í∑∏Î¶ΩÎã§\n","ÏïÑÎßà Í∑∏ Í≥≥ÏóêÏÑú ÎßéÏùÄ ÏÇ¨ÎûåÎì§Ïù¥ ÏßÄÎÇòÍ∞ÄÍ≥† Ïã∂ÏóàÎÇò Î≥¥Îã§\n","\n","==================================================\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"41aR0pxnjce7"},"source":["save2= pd.DataFrame({'keywords':keywords, 'texts': generated_texts})\n","save2.to_csv('daily_test.csv', encoding = 'utf-8-sig')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gkjZ6jlDpc4x","outputId":"6d7190c2-9058-4f40-d697-6526a0494a7f"},"source":["#ÎßàÏßÄÎßâ Î¨∏Ïû•Ïù¥ gptÏûÖÎ†•ÏúºÎ°ú Îì§Ïñ¥Í∞ê\n","generated_texts = []\n","keywords = ['ÌååÎ¶¨','Î∞§','ÏÇ∞Ï±Ö']\n","\n","for key in keywords:\n","    #input_data = input('ÌÇ§ÏõåÎìú ÏûÖÎ†• :')\n","    #keywords.append(input_data)\n","    sequence = key\n","    #keywords.append(input)\n","\n","    #max_len = 300\n","    total = ''\n","\n","    for i in input_data:\n","        max_len = 100\n","\n","        #print('input :' + i)\n","        #print('=' * 50)\n","        for j in range(3):\n","            g = generate_text(sequence, max_len)\n","            g = g.split('<eos>')[0]\n","            g = g.split(',')[2:]\n","            g = ', '.join(g)\n","\n","            t =''\n","            a = g.replace('.', '.&&')\n","            a = a.split('&&')\n","            data = a[:-1]\n","            if len(data)> 0:\n","                sequence = data[-1]\n","            for d in data: \n","                t += d + '\\n'\n","\n","            total += '\\n\\t' + t\n","            \n","    print('=' * 50)\n","    print(\"<generated_text>\")\n","    print(total)\n","    print('=' * 50)\n","    generated_texts.append(total)"],"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["loading configuration file ./models2/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n","  \"_num_labels\": 1,\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n","  \"bos_token_id\": 0,\n","  \"created_date\": \"2021-04-28\",\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"license\": \"CC-BY-NC-SA 4.0\",\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 3,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","loading weights file ./models2/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./models2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","Didn't find file ./models2/added_tokens.json. We won't load it.\n","loading file None\n","loading file ./models2/special_tokens_map.json\n","loading file ./models2/tokenizer_config.json\n","loading file ./models2/tokenizer.json\n","loading configuration file ./models2/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n","  \"_num_labels\": 1,\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n","  \"bos_token_id\": 0,\n","  \"created_date\": \"2021-04-28\",\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"license\": \"CC-BY-NC-SA 4.0\",\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 3,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","loading weights file ./models2/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./models2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","Didn't find file ./models2/added_tokens.json. We won't load it.\n","loading file None\n","loading file ./models2/special_tokens_map.json\n","loading file ./models2/tokenizer_config.json\n","loading file ./models2/tokenizer.json\n","loading configuration file ./models2/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n","  \"_num_labels\": 1,\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n","  \"bos_token_id\": 0,\n","  \"created_date\": \"2021-04-28\",\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"license\": \"CC-BY-NC-SA 4.0\",\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 3,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","loading weights file ./models2/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./models2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","Didn't find file ./models2/added_tokens.json. We won't load it.\n","loading file None\n","loading file ./models2/special_tokens_map.json\n","loading file ./models2/tokenizer_config.json\n","loading file ./models2/tokenizer.json\n","loading configuration file ./models2/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n","  \"_num_labels\": 1,\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n","  \"bos_token_id\": 0,\n","  \"created_date\": \"2021-04-28\",\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"license\": \"CC-BY-NC-SA 4.0\",\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 3,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","loading weights file ./models2/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./models2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","Didn't find file ./models2/added_tokens.json. We won't load it.\n","loading file None\n","loading file ./models2/special_tokens_map.json\n","loading file ./models2/tokenizer_config.json\n","loading file ./models2/tokenizer.json\n","loading configuration file ./models2/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n","  \"_num_labels\": 1,\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n","  \"bos_token_id\": 0,\n","  \"created_date\": \"2021-04-28\",\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"license\": \"CC-BY-NC-SA 4.0\",\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 3,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","loading weights file ./models2/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./models2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","Didn't find file ./models2/added_tokens.json. We won't load it.\n","loading file None\n","loading file ./models2/special_tokens_map.json\n","loading file ./models2/tokenizer_config.json\n","loading file ./models2/tokenizer.json\n","loading configuration file ./models2/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n","  \"_num_labels\": 1,\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n","  \"bos_token_id\": 0,\n","  \"created_date\": \"2021-04-28\",\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"license\": \"CC-BY-NC-SA 4.0\",\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 3,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","loading weights file ./models2/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./models2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","Didn't find file ./models2/added_tokens.json. We won't load it.\n","loading file None\n","loading file ./models2/special_tokens_map.json\n","loading file ./models2/tokenizer_config.json\n","loading file ./models2/tokenizer.json\n","loading configuration file ./models2/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n","  \"_num_labels\": 1,\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n","  \"bos_token_id\": 0,\n","  \"created_date\": \"2021-04-28\",\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"license\": \"CC-BY-NC-SA 4.0\",\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 3,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","loading weights file ./models2/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./models2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","Didn't find file ./models2/added_tokens.json. We won't load it.\n","loading file None\n","loading file ./models2/special_tokens_map.json\n","loading file ./models2/tokenizer_config.json\n","loading file ./models2/tokenizer.json\n","loading configuration file ./models2/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n","  \"_num_labels\": 1,\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n","  \"bos_token_id\": 0,\n","  \"created_date\": \"2021-04-28\",\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"license\": \"CC-BY-NC-SA 4.0\",\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 3,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","loading weights file ./models2/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./models2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","Didn't find file ./models2/added_tokens.json. We won't load it.\n","loading file None\n","loading file ./models2/special_tokens_map.json\n","loading file ./models2/tokenizer_config.json\n","loading file ./models2/tokenizer.json\n","loading configuration file ./models2/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n","  \"_num_labels\": 1,\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n","  \"bos_token_id\": 0,\n","  \"created_date\": \"2021-04-28\",\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"license\": \"CC-BY-NC-SA 4.0\",\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 3,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","loading weights file ./models2/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./models2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","Didn't find file ./models2/added_tokens.json. We won't load it.\n","loading file None\n","loading file ./models2/special_tokens_map.json\n","loading file ./models2/tokenizer_config.json\n","loading file ./models2/tokenizer.json\n","loading configuration file ./models2/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n","  \"_num_labels\": 1,\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n","  \"bos_token_id\": 0,\n","  \"created_date\": \"2021-04-28\",\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"license\": \"CC-BY-NC-SA 4.0\",\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 3,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","loading weights file ./models2/pytorch_model.bin\n"]},{"name":"stdout","output_type":"stream","text":["==================================================\n","<generated_text>\n","\n","\t Í∑∏Î¶¨Í≥† ÏóêÌé†ÌÉëÏùÑ Î≥º Ïàò ÏûàÎäî ÏàôÏÜåÎ°ú Ï∂îÏ≤úÌïúÎã§.\n","\n","ÏïÑÏπ® ÏùºÏ∞ç ÏàôÏÜåÏóê Îì§Ïñ¥Ïò® ÎçïÎ∂ÑÏù∏ÏßÄ ÌååÎ¶¨Ïùò ÏïÑÏπ®ÏùÄ Ï†úÎ≤ï ÏåÄÏåÄÌñàÎã§.\n","\n","Ïò§ÎäòÏùò Î©îÏù∏ÏùÄ ÏïÑÏπ®ÏãùÏÇ¨Î°ú ÎÇòÏò§Îäî ÏΩ©ÏΩîÎìú Í¥ëÏû•ÏóêÏÑú ÌïúÏãùÏù¥Îã§.\n","\n","ÌïúÏãùÏùÄ ÏßëÏóêÏÑú ÎßåÎìúÎäî ÍπÄÏπò Î≥¥Îã§ ÏßëÏóêÏÑú ÎßåÎìúÎäî ÍπÄÏπò ÎßõÏù¥ Ìõ®Ïî¨ Ï¢ãÎã§.\n","\n","ÌòºÏûêÏÑú Î®πÎäîÎç∞ÎèÑ ÏßàÎ¶¨ÏßÄ ÏïäÍ≥† Ï¢ãÏúºÎ©∞ ÌòºÏûê Î®πÏñ¥ÎèÑ ÏßàÎ¶¨ÏßÄ ÏïäÎã§.\n","\n","\t Í∑∏Î¶¨Í≥† ÏÜåÏä§Î•º Í≥ÅÎì§Ïù∏ ÏïÑÏπ® ÏãùÏÇ¨ ÎåÄÏö© ÏïÑÏπ® Î©îÎâ¥.\n",".\n","\n","\t\n","\t Í∑∏Îïê Ïù¥ÎØ∏ Í∑∏ Î™®Îì† Í≤ÉÏù¥ ÍøàÌãÄÎåÄÍ∏∞ ÏãúÏûëÌñàÏóàÎã§.\n","\n","Ïù¥Î≤à ÌååÎ¶¨ Ïó¨ÌñâÏóêÏÑúÎèÑ Í∑∏Îû¨Í≥† Í∑∏ÎïåÎèÑ Í∑∏Îû¨Í≥†.\n"," Ï†ÄÍ≤å ÏßÄÍ∏à ÏÇ¨ÏßÑÍ∏∞ ÏÜçÏóê ÎÇòÏò® Î™®ÏäµÏù¥ÏûñÏïÑ.\n","\n","ÏÇ¨Ïã§,  Í∑∏ ÎãπÏãúÎßå Ìï¥ÎèÑ ÎÇ¥ ÏÇ¨ÏßÑÏùÑ Î≥¥Í≥† Ïã∂Îã§Îäî ÏöïÎßùÏùÄ ÏûàÏóàÎäîÎç∞,  Í∑∏ ÏãúÏ†à ÎÇ¥ ÏÇ¨ÏßÑÏùÑ Î≥¥Î©¥ÏÑú Ïù¥Í≤å Ïõ¨ Îñ°Ïù¥ÎûÄÎã§Îäî ÏÉùÍ∞ÅÏùÑ ÌñàÏóàÎã§.\n","\n","\t  Í∑∏ ÏãúÏ†à ÎÇ¥ ÏÇ¨ÏßÑÏùÑ Î≥¥Î©¥ÏÑú Ïù¥Í≤å Ïõ¨ Îñ°Ïù¥ÎûÄÎã§Îäî ÏÉùÍ∞ÅÏùÑ ÌñàÏóàÎã§.\n",", \n","ÎçîÏö±Ïù¥ ÌååÎ¶¨Ïó¨Ìñâ Ï§ë ÌååÎ¶¨Ïóê Í∞Ñ ÎÇ†ÏùÄ ÎπÑÌñâÍ∏∞Í∞Ä Ï†ÄÎÖÅ Ï¶àÏùåÏóê ÎèÑÏ∞©ÌïòÎäî Î∞îÎûåÏóê ÎçîÎçîÏö± ÎÇ¥Í∞Ä Î≥¥Í≥† Ïã∂ÏóàÍ≥†, \n","ÎÇòÏ§ëÏóê Í∏∞ÏñµÏùÑ ÎêòÏÇ¥Î¶¨Î©¥ Îê† Í±∞ Í∞ôÎã§.\n","\n","Í∑∏ÎûòÏÑú,  Í∑∏ÎïåÎäî ÎÇòÏùò ÏÇ¨ÏßÑÍ≥º Ïó¨Ìñâ ÌõÑÍ∏∞Î•º Ìï®Íªò Ïì∞ÏûêÍ≥† Ï†úÏïàÌñàÎã§.\n","\n","Ï†ïÎßê,  Í∑∏ÎïåÎäî ÌòºÏûêÏòÄÎã§.\n","\n","\t.\n",".\n","\n","Ï≤òÏùåÏóêÎäî ÏóÑÎßàÎ•º Î™®ÏãúÍ≥† ÌååÎ¶¨Ïó¨ÌñâÏùÑ Í∞îÎçò Ï†ÅÏù¥ ÏûàÏäµÎãàÎã§.\n","\n","Ï≤òÏùåÏóêÎäî Í∑∏ÎÉ• ÌòºÏûêÏòÄÍ∏∞ ÎïåÎ¨∏Ïóê ÌòºÏûêÏòÄÍ∏∞ ÎïåÎ¨∏Ïóê ÏóÑÎßàÏùò ÏßëÏùÑ ÎìúÎÇòÎì§ÏóàÏùÑ ÎøêÏù¥ÏóàÏßÄÎßå Ïù¥Ï†úÎäî ÏóÑÎßàÏùò ÎßàÏùåÎèÑ ÎÇòÏ§ëÏóî ÎÇ¥ ÎßàÏùå Í∞ôÏù¥ ÎäêÍª¥Ï°åÏäµÎãàÎã§.\n","\n","ÏùºÎèÑ Ï†úÎ≤ï ÌÅ¨Í≤å ÎäêÍ∏ãÌïòÍ≤å ÏãúÏûëÌñàÏúºÎãàÍπåÏöî.\n","\n","Ï≤òÏùåÏóî ÏóÑÎßàÏôÄ ÎààÏùÑ ÎßûÏ∂∞ÏïºÍ≤†Îã§Îäî ÏÉùÍ∞ÅÏù¥ Îì§ÏóàÎäîÎç∞ ÏÇ¨Ïã§ ÏóÑÎßàÎäî Ï†ÑÌòÄ Í∑∏Îü∞ Í≥ÑÌöçÏù¥ ÏóÜÏóàÏóàÏ£†.\n","\n","\t\n","\t Í∑∏ÎÇ†Ïùò Ï†ÄÎÖÅÏùÄ ÎπµÏßë ÏïûÏóê ÏïâÏïÑÏÑú Í∞ÑÎã®Ìûà Î∏åÎü∞ÏπòÎ•º Ï¶êÍ∏∞Îçò ÏóÑÎßàÏôÄ ÎÇòÎäî Ïû†Ïãú ÎààÏãúÏö∏ÏùÑ Î∂âÌòîÏ£†.\n","\n","Ïù¥Î≤àÏóêÎäî ÏóÑÎßàÏùò ÏïàÏã¨Ïù¥ ÌïÑÏöîÌñàÏ£†.\n","\n","Ïö∞Î¶¨Ïùò Ïó¨ÌñâÏùò ÌõÑÎ∞òÎ∂ÄÏóêÏÑ† Îã§Ïãú ÏóÑÎßàÏôÄ ÎààÏùÑ ÎßûÏ∂∞ÏïºÍ≤†Îã§Îäî ÏÉùÍ∞ÅÏù¥ Îì§ÏóàÍ±∞Îì†Ïöî.\n","\n","\t\n","ÎßàÏùå Í∞ôÏïÑÏÑúÎäî Ïó¨ÌñâÏùÑ Îã§ÎÖÄÏò§Í∏∞Î°ú ÌñàÏñ¥Ïöî.\n","\n","ÏóÑÎßàÏôÄ Ïó¨ÌñâÏùÑ Ìï®ÍªòÌïòÍ∏∞Î°ú ÌñàÏúºÎãà ÏóÑÎßàÎäî Íº≠ Ï¢ãÏùÄ Í≥≥Ïóê Îã§ÎÖÄÏò§ÎùºÍ≥† Í≤©Î†§Ìï¥ Ï£ºÏÖ®Ïñ¥Ïöî.\n","\n","Í∑∏Í≤å Ïñ¥Îäê Ï†ïÎèÑ Ïïà ÎêêÏùÑ Îïå, \n","Ïù¥Îü∞ ÎßêÏùÑ Îì§ÏúºÎãà Ï†ÄÎèÑ ÎßàÏùåÏù¥ Ï∞°Ìïú Í≤å ÏÇ¨Ïã§Ïù∏Îç∞Ïöî.\n","\n","==================================================\n"]},{"name":"stderr","output_type":"stream","text":["All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./models2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","Didn't find file ./models2/added_tokens.json. We won't load it.\n","loading file None\n","loading file ./models2/special_tokens_map.json\n","loading file ./models2/tokenizer_config.json\n","loading file ./models2/tokenizer.json\n","loading configuration file ./models2/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n","  \"_num_labels\": 1,\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n","  \"bos_token_id\": 0,\n","  \"created_date\": \"2021-04-28\",\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"license\": \"CC-BY-NC-SA 4.0\",\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 3,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","loading weights file ./models2/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./models2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","Didn't find file ./models2/added_tokens.json. We won't load it.\n","loading file None\n","loading file ./models2/special_tokens_map.json\n","loading file ./models2/tokenizer_config.json\n","loading file ./models2/tokenizer.json\n","loading configuration file ./models2/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n","  \"_num_labels\": 1,\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n","  \"bos_token_id\": 0,\n","  \"created_date\": \"2021-04-28\",\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"license\": \"CC-BY-NC-SA 4.0\",\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 3,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","loading weights file ./models2/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./models2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","Didn't find file ./models2/added_tokens.json. We won't load it.\n","loading file None\n","loading file ./models2/special_tokens_map.json\n","loading file ./models2/tokenizer_config.json\n","loading file ./models2/tokenizer.json\n","loading configuration file ./models2/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n","  \"_num_labels\": 1,\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n","  \"bos_token_id\": 0,\n","  \"created_date\": \"2021-04-28\",\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"license\": \"CC-BY-NC-SA 4.0\",\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 3,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","loading weights file ./models2/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./models2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","Didn't find file ./models2/added_tokens.json. We won't load it.\n","loading file None\n","loading file ./models2/special_tokens_map.json\n","loading file ./models2/tokenizer_config.json\n","loading file ./models2/tokenizer.json\n","loading configuration file ./models2/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n","  \"_num_labels\": 1,\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n","  \"bos_token_id\": 0,\n","  \"created_date\": \"2021-04-28\",\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"license\": \"CC-BY-NC-SA 4.0\",\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 3,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","loading weights file ./models2/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./models2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","Didn't find file ./models2/added_tokens.json. We won't load it.\n","loading file None\n","loading file ./models2/special_tokens_map.json\n","loading file ./models2/tokenizer_config.json\n","loading file ./models2/tokenizer.json\n","loading configuration file ./models2/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n","  \"_num_labels\": 1,\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n","  \"bos_token_id\": 0,\n","  \"created_date\": \"2021-04-28\",\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"license\": \"CC-BY-NC-SA 4.0\",\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 3,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","loading weights file ./models2/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./models2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","Didn't find file ./models2/added_tokens.json. We won't load it.\n","loading file None\n","loading file ./models2/special_tokens_map.json\n","loading file ./models2/tokenizer_config.json\n","loading file ./models2/tokenizer.json\n","loading configuration file ./models2/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n","  \"_num_labels\": 1,\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n","  \"bos_token_id\": 0,\n","  \"created_date\": \"2021-04-28\",\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"license\": \"CC-BY-NC-SA 4.0\",\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 3,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","loading weights file ./models2/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./models2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","Didn't find file ./models2/added_tokens.json. We won't load it.\n","loading file None\n","loading file ./models2/special_tokens_map.json\n","loading file ./models2/tokenizer_config.json\n","loading file ./models2/tokenizer.json\n","loading configuration file ./models2/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n","  \"_num_labels\": 1,\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n","  \"bos_token_id\": 0,\n","  \"created_date\": \"2021-04-28\",\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"license\": \"CC-BY-NC-SA 4.0\",\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 3,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","loading weights file ./models2/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./models2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","Didn't find file ./models2/added_tokens.json. We won't load it.\n","loading file None\n","loading file ./models2/special_tokens_map.json\n","loading file ./models2/tokenizer_config.json\n","loading file ./models2/tokenizer.json\n","loading configuration file ./models2/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n","  \"_num_labels\": 1,\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n","  \"bos_token_id\": 0,\n","  \"created_date\": \"2021-04-28\",\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"license\": \"CC-BY-NC-SA 4.0\",\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 3,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","loading weights file ./models2/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./models2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","Didn't find file ./models2/added_tokens.json. We won't load it.\n","loading file None\n","loading file ./models2/special_tokens_map.json\n","loading file ./models2/tokenizer_config.json\n","loading file ./models2/tokenizer.json\n","loading configuration file ./models2/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n","  \"_num_labels\": 1,\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n","  \"bos_token_id\": 0,\n","  \"created_date\": \"2021-04-28\",\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"license\": \"CC-BY-NC-SA 4.0\",\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 3,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","loading weights file ./models2/pytorch_model.bin\n"]},{"name":"stdout","output_type":"stream","text":["==================================================\n","<generated_text>\n","\n","\t\n","\t Í±∞Î¶¨Ïùò ÏïÖÏÇ¨Îì§ÎèÑ Ìï®Íªò ÎÇòÏôÄ Í±∞Î¶¨Î°ú ÏèüÏïÑÏ†∏ ÎÇòÏôîÎã§.\n","\n","Í∑∏Îü∞Îç∞ Ïù¥ÏÉÅÌïòÍ≤åÎèÑ Î™ΩÎßàÎ•¥Ìä∏Î•¥ Ïñ∏ÎçïÏóê ÏûàÎçò ÎßéÏùÄ ÏÇ¨ÎûåÎì§Ïù¥ Í±∞Î¶¨Î•º ÎπÑÏßëÍ≥† Îì§Ïñ¥Ïò® Í≤ÉÏù¥Îã§.\n","\n","Í∑∏Î¶¨Í≥† Í∑∏ Î™®ÏäµÏùÑ Î≥¥Î©∞ ÎÇòÎèÑ Î™®Î•¥Í≤å'Ïñ¥Ïß∏ÏÑú Í∏∏ÏùÑ Í±∏ÏùÄ Í±∞ÏßÄ?'ÌïòÎäî ÏÉùÍ∞ÅÏù¥ Îì§ÏóàÎã§.\n","\n","\t ÌååÎ¶¨Ïóê ÎèÑÏ∞©ÌñàÏùÑ Îïå,  Ïö∞Ïó∞Ìûà ÎßàÏ£ºÏπú Î∞òÍ∞ÄÏõÄÍ≥º ÏÑ§Î†àÎäî Í∞êÏ†ïÏùÑ.\n",".\n",".\n",".\n",".\n"," Í∑∏Îïå,  ÎÇòÏùò ÌååÎ¶¨.\n",".\n",".\n",".\n",".\n","\n","\t ÌîÑÎûëÏä§ Ïä§ÏºÄÏπò - ÌååÎ¶¨ ÏÉπÏ†§Î¶¨Ï†ú Í±∞Î¶¨'Ìé∏ÏùÑ ÏãúÏûëÏúºÎ°ú Ïó¨Îü¨Î∂ÑÍ≥º ÌîÑÎûëÏä§ Ïó¨ÌñâÏùÑ Îñ†ÎÇ©ÎãàÎã§.\n","\n","Îã§Ïãú ÌååÎ¶¨Ïóê ÏôÄÏÑú Î™ΩÎßàÎ•¥Ìä∏Î•¥ Ïñ∏ÎçïÍ≥º ÏóêÌé†ÌÉë Í∑∏Î¶¨Í≥† ÏÑº Í∞ïÏùò ÎÇ≠ÎßåÏùÑ Ï¶êÍ∏∏ Ïàò ÏûàÎã§Î©¥,  ÌååÎ¶¨Î•º Í∞ÄÏû• ÏïÑÎ¶ÑÎãµÍ≤å ÎßåÎì§ ÏàòÎäî ÏóÜÏùÑÍπåÏöî?\n","ÏïÑÎßàÎèÑ Í∑∏Îïå,  Îòê Í∑∏Îïê'ÏßÄÍ∏àÏù¥ ÌååÎ¶¨ÏóêÏÑú Í∞ÄÏû• ÏïÑÎ¶ÑÎã§Ïö¥'Í≤É Í∞ôÏúºÎãàÍπåÏöî.\n","\n","\t  Îòê Í∑∏Îïê'ÏßÄÍ∏àÏù¥ ÌååÎ¶¨ÏóêÏÑú Í∞ÄÏû• ÏïÑÎ¶ÑÎã§Ïö¥'Í≤É Í∞ôÏúºÎãàÍπåÏöî.\n",", \n","Í∑∏Î†áÍ≤å Î™ΩÎßàÎ•¥Ìä∏Î•¥ Ïñ∏ÎçïÏóê Ïò¨Îùº ÏóêÌé†ÌÉëÏùò ÏïºÍ≤ΩÍ≥º ÌååÎ¶¨Ïùò Î∞§ÏùÑ Í∞êÏÉÅÌïòÎ©∞,  ÎÇ¥Ïùº Îã§Ïãú ÌååÎ¶¨Ïóê Ïò§Í≤†ÏäµÎãàÎã§.\n","\n","\t  ÎÇ¥Ïùº Îã§Ïãú ÌååÎ¶¨Ïóê Ïò§Í≤†ÏäµÎãàÎã§.\n",", \n","ÎßàÏßÄÎßâÏúºÎ°ú,  ÏÑºÍ∞ïÏùÑ Îî∞Îùº Ï≤úÏ≤úÌûà ÏÉπÏ†§Î¶¨Ï†ú Í±∞Î¶¨Î•º Í±∏ÏúºÎ©∞ Ïó¨Îü¨Î∂ÑÍªò Îã§Ïãú Ïù∏ÏÇ¨Î•º ÎìúÎ¶¨Í≤†ÏäµÎãàÎã§!\n","| skiprance |\n","| Î•¥ ÏÖÄÎ†âÌä∏ | ÏÑºÍ∞ï ÎÅùÏûêÎùΩ | ÌååÎ¶¨ | ÎèÑÏã¨ÏùÑ ÎèåÏïÑÎ≥¥Îäî Ïó¨Ìñâ Î∞©Î≤ïÏùÄ Ïù¥Î†áÏäµÎãàÎã§.\n","\n","\t  ÏÑºÍ∞ïÏùÑ Îî∞Îùº Ï≤úÏ≤úÌûà ÏÉπÏ†§Î¶¨Ï†ú Í±∞Î¶¨Î•º Í±∏ÏúºÎ©∞ Ïó¨Îü¨Î∂ÑÍªò Îã§Ïãú Ïù∏ÏÇ¨Î•º ÎìúÎ¶¨Í≤†ÏäµÎãàÎã§!\n","| skiprance |\n","| Î•¥ ÏÖÄÎ†âÌä∏ | ÏÑºÍ∞ï ÎÅùÏûêÎùΩ | ÌååÎ¶¨ | ÎèÑÏã¨ÏùÑ ÎèåÏïÑÎ≥¥Îäî Ïó¨Ìñâ Î∞©Î≤ïÏùÄ Ïù¥Î†áÏäµÎãàÎã§.\n","\n","\t\n","\t\n","==================================================\n"]},{"name":"stderr","output_type":"stream","text":["All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./models2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","Didn't find file ./models2/added_tokens.json. We won't load it.\n","loading file None\n","loading file ./models2/special_tokens_map.json\n","loading file ./models2/tokenizer_config.json\n","loading file ./models2/tokenizer.json\n","loading configuration file ./models2/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n","  \"_num_labels\": 1,\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n","  \"bos_token_id\": 0,\n","  \"created_date\": \"2021-04-28\",\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"license\": \"CC-BY-NC-SA 4.0\",\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 3,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","loading weights file ./models2/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./models2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","Didn't find file ./models2/added_tokens.json. We won't load it.\n","loading file None\n","loading file ./models2/special_tokens_map.json\n","loading file ./models2/tokenizer_config.json\n","loading file ./models2/tokenizer.json\n","loading configuration file ./models2/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n","  \"_num_labels\": 1,\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n","  \"bos_token_id\": 0,\n","  \"created_date\": \"2021-04-28\",\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"license\": \"CC-BY-NC-SA 4.0\",\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 3,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","loading weights file ./models2/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./models2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","Didn't find file ./models2/added_tokens.json. We won't load it.\n","loading file None\n","loading file ./models2/special_tokens_map.json\n","loading file ./models2/tokenizer_config.json\n","loading file ./models2/tokenizer.json\n","loading configuration file ./models2/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n","  \"_num_labels\": 1,\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n","  \"bos_token_id\": 0,\n","  \"created_date\": \"2021-04-28\",\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"license\": \"CC-BY-NC-SA 4.0\",\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 3,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","loading weights file ./models2/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./models2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","Didn't find file ./models2/added_tokens.json. We won't load it.\n","loading file None\n","loading file ./models2/special_tokens_map.json\n","loading file ./models2/tokenizer_config.json\n","loading file ./models2/tokenizer.json\n","loading configuration file ./models2/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n","  \"_num_labels\": 1,\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n","  \"bos_token_id\": 0,\n","  \"created_date\": \"2021-04-28\",\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"license\": \"CC-BY-NC-SA 4.0\",\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 3,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","loading weights file ./models2/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./models2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","Didn't find file ./models2/added_tokens.json. We won't load it.\n","loading file None\n","loading file ./models2/special_tokens_map.json\n","loading file ./models2/tokenizer_config.json\n","loading file ./models2/tokenizer.json\n","loading configuration file ./models2/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n","  \"_num_labels\": 1,\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n","  \"bos_token_id\": 0,\n","  \"created_date\": \"2021-04-28\",\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"license\": \"CC-BY-NC-SA 4.0\",\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 3,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","loading weights file ./models2/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./models2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","Didn't find file ./models2/added_tokens.json. We won't load it.\n","loading file None\n","loading file ./models2/special_tokens_map.json\n","loading file ./models2/tokenizer_config.json\n","loading file ./models2/tokenizer.json\n","loading configuration file ./models2/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n","  \"_num_labels\": 1,\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n","  \"bos_token_id\": 0,\n","  \"created_date\": \"2021-04-28\",\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"license\": \"CC-BY-NC-SA 4.0\",\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 3,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","loading weights file ./models2/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./models2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","Didn't find file ./models2/added_tokens.json. We won't load it.\n","loading file None\n","loading file ./models2/special_tokens_map.json\n","loading file ./models2/tokenizer_config.json\n","loading file ./models2/tokenizer.json\n","loading configuration file ./models2/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n","  \"_num_labels\": 1,\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n","  \"bos_token_id\": 0,\n","  \"created_date\": \"2021-04-28\",\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"license\": \"CC-BY-NC-SA 4.0\",\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 3,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","loading weights file ./models2/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./models2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","Didn't find file ./models2/added_tokens.json. We won't load it.\n","loading file None\n","loading file ./models2/special_tokens_map.json\n","loading file ./models2/tokenizer_config.json\n","loading file ./models2/tokenizer.json\n","loading configuration file ./models2/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n","  \"_num_labels\": 1,\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n","  \"bos_token_id\": 0,\n","  \"created_date\": \"2021-04-28\",\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"license\": \"CC-BY-NC-SA 4.0\",\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"pad_token_id\": 3,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","loading weights file ./models2/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./models2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","Didn't find file ./models2/added_tokens.json. We won't load it.\n","loading file None\n","loading file ./models2/special_tokens_map.json\n","loading file ./models2/tokenizer_config.json\n","loading file ./models2/tokenizer.json\n"]},{"name":"stdout","output_type":"stream","text":["==================================================\n","<generated_text>\n","\n","\t ÏÇ∞Ï±ÖÏùÑ ÌïòÎ©∞ ÏÇ¥Í≥† ÏûàÏóàÎã§.\n","\n","Ï°∞Ïö©Ìûà Ïûò Î≥¥ÎÇ¥Í≥† Ïã∂ÏùÄ ÎßàÏùåÏóê Î∞ñÏúºÎ°ú ÎÇòÍ∞ÄÎ≥¥Îãà Ïñ¥ÎäêÏÉà Ïù¥Î•∏ Í≤®Ïö∏Ïù¥ÎùºÏÑú Í∏∏ÏùÑ Ï∞æÏßÄ Î™ªÌï¥ Ìó§Îß§Îã§Í∞Ä ÏàôÏÜåÏóê ÎèÑÏ∞©ÌñàÎã§.\n","\n","ÏàôÏÜåÏóê Îì§Ïñ¥ÏÑúÎãà Îî∞ÎúªÌïú Î∞îÎûåÏù¥ ÎÇòÎ•º Í∏∞Î∂Ñ Ï¢ãÍ≤å ÌñàÎã§.\n","\n","Ï†ÄÎÖÅ Î®πÍ≥† Ïã∂ÏùÄ Îç∞Í∞Ä Î™á Íµ∞Îç∞ ÏûàÏñ¥ÏÑú ÎÇòÍ∞ÄÎãà Ï°∞Í≥§Ï°∞Í≥§ ÎπÑÍ∞Ä ÎÇ¥Î¶¨Í∏∞ ÏãúÏûëÌñàÎã§.\n","\n","Í∑∏ÎÉ• Ïö∞ÏÇ∞ÏùÑ Ïì∞Í≥† ÏôîÎäîÎç∞ ÎπÑÍ∞Ä ÎÑàÎ¨¥ ÎßéÏù¥ Ïò®Îã§Í≥† Ìï¥ÏÑú Ïö∞ÏÇ∞ÏùÑ ÏÇ¨ÏÑú Í∞ÑÍ±∞Îã§.\n","\n","\t ÎπÑÍ∞Ä ÎßéÏù¥ Ïò§Îãà ÏßêÏùÑ ÏååÎã§Í∞Ä ÎπÑÍ∞Ä ÎÑàÎ¨¥ ÎßéÏù¥ ÏôÄÏÑú Ïñ¥Ï©î Ïàò ÏóÜÏù¥ Ïö∞ÏÇ∞ÏùÑ Î∫êÎã§.\n","\n","\t\n","\t Ìò∏ÏÑ† Î∞îÏä§Ìã∞Ïú† Ïó≠ÏóêÏÑú Ìò∏ÏÑ†ÏúºÎ°ú Í∞àÏïÑÌÉÄÍ≥†,  Ìò∏ÏÑ† Î°±ÎπÑÏπòÏóê Îã§Ïãú ÏßÄÌïòÏ≤† Ïó≠ÏúºÎ°ú Í∞àÏïÑÌÉîÎã§.\n","\n","\t Î™ΩÎßàÎ•¥Ìä∏Î•¥ Ïñ∏ÎçïÏùÄ Ï†ïÎßê Ï¢ãÏïòÎã§.\n","\n","Í∑∏Î¶¨Í≥† ÏßÄÍ∏à Î™ΩÎßàÎ•¥Ìä∏Î•¥ Ïñ∏ÎçïÏóêÏÑú Í∞ÄÏû• ÎÜíÏùÄ Í≥≥Ïóê ÏúÑÏπòÌïú Î§ΩÏÉÅÎ∂ÄÎ•¥ Ï†ïÏõêÏóêÏÑúÎäî ÌååÎ¶¨ Ïó¨ÌñâÏùò ÏãúÏûëÏùÑ ÏïåÎ¶¨Îäî Î∂àÍΩÉÏù¥ ÏöîÎûÄÌïòÍ≤å Î∂àÏóàÎã§.\n","\n","Ïö∞Î¶¨ÎÇòÎùºÏóêÎäî ÌååÎ¶¨ Ïô∏ÏóêÎèÑ ÎåÄÏö¥ÌïòÎ•º ÎëêÍ≥† Ïó¨Îü¨ Í≥≥Îì§Ïù¥ Í≥µÏÇ¨ Ï§ëÏù¥ÏóàÎã§.\n","\n","\t Î£®Î∏åÎ•¥ Î∞ïÎ¨ºÍ¥Ä,  ÎùºÎç∞Ìå°Ïä§,  ÌêÅÌîºÎëê ÏÑºÌÑ∞,  ÏóêÌé† ÌÉÄÏõå,  ÌêÅÌîºÎëê ÏÑºÌÑ∞,  ÏÉπÏ†§Î¶¨Ï†ú Í±∞Î¶¨,  ÏóêÌé† ÌÉÄÏõå,  Î≤†Î•¥ÏÇ¨Ïú† Í∂ÅÏ†ÑÎèÑ ÏûàÎã§.\n","\n","Îòê,  ÌååÎ¶¨ ÏãúÎÇ¥ Ï†ÑÍ≤ΩÏùÑ Í∞êÏÉÅÌïòÎ©¥ÏÑú Î£®Î∏åÎ•¥ Î∞ïÎ¨ºÍ¥ÄÏùò Ï§ëÏöî ÏûëÌíàÏùÑ Í∞êÏÉÅÌïòÎ©¥ÏÑú ÌååÎ¶¨ ÏãúÎÇ¥ Ï†ÑÍ≤ΩÏùÑ Î∞îÎùºÎ≥º Ïàò ÏûàÎäî Ï†ÑÎßùÎåÄÎèÑ ÏûàÎã§.\n","\n","\t,  Î£®Î∏åÎ•¥ Î∞ïÎ¨ºÍ¥Ä Ïô∏ÏóêÎèÑ ÏÑº Í∞ïÏùÑ Í∞ÄÎ°úÏßÄÎ•¥Îäî ÏÑº Í∞ï ÏÑº Í∞ïÏùò Ïú†ÎûåÏÑ†,  ÎÖ∏Ìä∏Î•¥Îã¥ ÏÑ±Îãπ,  ÏÉùÌä∏ ÏÉ§Ìé†ÏóêÏÑú ÎèÑÎ≥¥ Î∂Ñ ÎÇ¥Ïóê Ïù¥ÎèôÌï† Ïàò ÏûàÎäî Ïó≠ÏÑ∏Í∂åÎèÑ Ìï®Íªò ÏúÑÏπòÌï¥ ÏûàÏñ¥ ÌååÎ¶¨Ïùò Î™®Îì† Í≥≥ÏùÑ Ïù¥ÎèôÌï† Ïàò ÏûàÎã§.\n",",  ÎåÄÏ§ëÍµêÌÜµ Ïù¥Ïö©Ïù¥ Ìé∏Î¶¨ÌïòÍ≥†,  Î£®Î∏åÎ•¥ Î∞ïÎ¨ºÍ¥ÄÍ≥º Ïù∏Ï†ëÌï¥ ÏûàÏñ¥ ÌååÎ¶¨Ïùò Î™®Îì† Í≥≥ÏùÑ ÏûêÏú†Î°≠Í≤å Ïù¥ÎèôÌï† Ïàò ÏûàÎã§.\n","\n","\t  Î£®Î∏åÎ•¥ Î∞ïÎ¨ºÍ¥ÄÍ≥º Ïù∏Ï†ëÌï¥ ÏûàÏñ¥ ÌååÎ¶¨Ïùò Î™®Îì† Í≥≥ÏùÑ ÏûêÏú†Î°≠Í≤å Ïù¥ÎèôÌï† Ïàò ÏûàÎã§.\n",", \n","Ï°∞Ïãù Î∞è Í∞ÅÏ¢Ö Í∏∞ÎÖêÌíàÎèÑ Ï§ÄÎπÑÎêòÏñ¥ ÏûàÎã§.\n","\n","Í∞ÄÍ≤©ÏùÄ Î∞ï Îßå ÏõêÎåÄ.\n"," Îùº ÎπÑÏóêÏäà Ìò∏Ïä§ÌÖåÏù¥Ìä∏ Í∞ùÏã§ÏóêÏÑú ÏóêÌé†ÌÉëÏùÑ Î≥º Ïàò ÏûàÎäî Ìà¨Î¶¨Ï¶àÎ©î Î∞îÍ∞Ä Î¨¥Î£å Ï†úÍ≥µÎêúÎã§.\n","\n","ÏûÖÍµ¨ÏôÄ ÌÖåÎùºÏä§ÎèÑ Ïù∏Í∏∞Í∞Ä ÏûàÎã§.\n","\n","\t ÏãùÍ∏∞ÏÑ∏Ï≤ôÍ∏∞ Îì± Í∞ÑÎã®Ìïú Ï°∞Î¶¨Í∞Ä Í∞ÄÎä•Ìïú Ï†úÌíàÏùÑ Íµ¨ÏûÖÌïòÏûê.\n","\n","ÏãùÍ∏∞ÏÑ∏Ï≤ôÍ∏∞,  Ï†ÑÏûêÎ†àÏù∏ÏßÄ,  ÏôÄÏù∏Î≥ë Îì± Ï£ºÎ∞©Ïö©ÌíàÏùÑ Ìï©Î¶¨Ï†ÅÏù∏ Í∞ÄÍ≤©Ïóê Íµ¨ÏûÖÌïòÏûê.\n","\n","Ï°∞ÏãùÏùÄ Î∑îÌéòÏôÄ ÎπÑÏä∑ÌïòÏßÄÎßå Î∑îÌéòÎ≥¥Îã§Îäî Ï†ÄÎ†¥Ìïú Í∞ÄÍ≤©Ïù¥Î©∞ ÎîîÎÑàÍ∞Ä Í∞ÄÎä•ÌïòÍ∏∞Ïóê Î∑îÌéòÎ≥¥Îã§ ÎîîÎÑàÎ•º Ï∂îÏ≤úÌïòÎäî Ìé∏Ïù¥Îã§.\n","\n","==================================================\n"]}]},{"cell_type":"code","metadata":{"id":"vJLakiQSvcUd"},"source":["for idx in range(len(generated_texts)):\n","    temp = ''\n","    gen = generated_texts[idx].split('\\n')\n","    for s in gen:\n","        s = s.strip()\n","        temp += s +'\\n'\n","    generated_texts[idx]= temp \n","\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jLZ0dya3vqBt"},"source":["save2= pd.DataFrame({'keywords':keywords, 'texts': generated_texts})\n","save2.to_csv('daily_input_connected.csv', encoding = 'utf-8-sig')"],"execution_count":null,"outputs":[]}]}